Your proposal/plan should include the following sections:

1. Description of the data you will analyze: number of variables, number of rows/instances available to you.  Create a table and for each variable describe: name, type (categorical, continuous) or nominal, ordinal, interval, ratio, maximum value, minimum value, some measure of central tendency, number of instances of each value of categorical data, a visualization of each variables data (to identify minority classes)  Note if your data has too many variables you can use a subset.  Rules: your data set must include at least 10 variables and at least one must be text in nature. 
2. Evidence that you have the data set to use for your project.    You can upload the data set as a CSV file or if you cannot share it, just provide a snapshot of part of it.
3. Predictive analytics requires predicting something. What are you trying to predict? group membership? a value?  Which variable in your data is the thing you will predict (the class)?  For example in the weather database the thing you are trying to predict is play (yes/no).
4. The model development process requires 3 subsets of data: development/training, testing and validation or "bake off"  One source recommends "64% of the original data for training, 16% for "validation," and 20% (!) for the final [validation] holdout." 
5. What problems do you see in your data?  All data have problems, so "no problems" is not an acceptable answer.  Discuss missing values, undefined variables, minority classes within variables, biases created by lack of inclusion of some populations.
6. Sampling:  What methodology will you use to create your development/testing sample (random, stratified) and how will it cope with the minority values in your data?  Default is random unless you have identified important minority data values in your data set.  Don't worry about how to implement this sampling yet.  You will do the sampling in a future week.
7. What is your strategy to ensure you will have sufficient data for testing and final validation?  Maybe you have tons of data so it is easy, but maybe you don't have much data so it may be hard.   For testing, I assume most of you will use the default "10 fold cross validation" strategy in WEKA.  (In most cases, using the default 10 fold cross validation strategy will work great)  For validation you may want to keep a subset file separate and then only add it to WEKA late in the semester for validation purposes (using the supplied data set approach we did in synch session 5)
8. Given the nature of what you want to predict, explain whether false positives or false negatives would be more damaging and explain why?  Note this may be hard to answer if you haven't figured out what you are predicting yet.  If you know what you are predicting, try to think about the $ costs, reputation costs, and ethics of making wrong predictions. 
-You do not need to say whether you hope to do cluster, trees etc at this point.
